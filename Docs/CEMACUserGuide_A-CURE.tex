\newcommand{\Project}{A-CURE}
%%%%%%%%%%%%% YOU SHOULDN'T AHVE TO MODIFY THE FOLLOWING SECTION %%%%%%%%%%%
%%%%%%%%%%%%% (UNLESS YOU WANT TO ADD BESPOKE PACKAGES) %%%%%%%%%%%%%%%%%%%%
\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{setspace}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{geometry}
\newcommand\tab[1][0.5cm]{\hspace*{#1}}
\renewcommand{\baselinestretch}{1.5}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\renewcommand\labelitemii{$\circ$}
\renewcommand\labelitemiii{\scalebox{0.5}{$\blacksquare$}}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{CEMAC User Documentation}
\lfoot{\leftmark}
\rfoot{Page \thepage}
\rhead{\Project}  
\begin{document}
\begin{center}
\vspace*{0.5cm}
{\Huge CEMAC User Documentation: \Project}
\end{center}
\vspace*{0.5cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Python scripts}

\subsection{pp2nc\_AOD550\_CDN.py}

\subsubsection{Purpose}

Extract and condense information from 3-hourly, daily or monthly pp files belonging to the UKCA26AER
         perturbed parameter ensemble (PPE) set into netCDF format. One set of netCDF files
         contains aerosol optical depth (AOD) at 550nm, and another set contains column-integrated
         cloud droplet number concentration (CDNC) fields for all 235 PPE members on a coarsened
         grid (N96 down to N48). If processing 3-hourly or daily pp files, there is one nc file per day;
         if processing monthly files, there is one nc file per month.

\subsubsection{Usage}
The script can be run from the command line as follows:\\
\tab \texttt{\$ ./pp2nc\_AOD550\_CDN.py <timeRes> <ppRoot> <orogFile> <ncRef> <ncRoot> <startDate> <endDate>}\\
where:
\begin{itemize}
\item \texttt{<timeRes>} is the time resolution of the pp files, either `3hrly', `daily' or `monthly'
\item \texttt{<ppRoot>} is the path (either relative to the current directory, or full) to the root directory containing the pp files. The expected file naming convention under this root directory is described further below.
\item \texttt{<orogFile>} is the path (relative or full) to the ancillary UM file containing the orography data associated with the pp files (file typically called `qrparm.orog').
\item \texttt{<ncRef>} is the path (relative or full) to a reference netCDF file whose coordinate system is at the desired coarsened resolution (N48) onto which the original high-resolution (N96) data should be regridded.
\item \texttt{<ncRoot>} is the path (relative or full) to the desired output directory.
\item \texttt{<startDate>} is in the format YYYYMMDD for 3hrly or daily pp files, or YYYYMM for monthly pp files, and refers to the first day/month (inclusive) to be processed.
\item \texttt{<endDate>} is in the format YYYYMMDD for 3hrly or daily pp files, or YYYYMM for monthly pp files, and refers to the last day/month (inclusive) to be processed.
\end{itemize}
It is also possible to see the above information in the terminal by typing:\\
\tab \texttt{\$ ./pp2nc\_AOD550\_CDN.py --help}

\subsubsection{Dependencies}
The script has been designed to run on the JASMIN analysis servers and/or LOTUS (which have access to the pp files that reside in the GASSP/UKCA group workspaces). Running the script will automatically choose the python2.7 interpreter, as it is this version of python that has access to all the scientific packages (e.g. IRIS) installed on JASMIN.\\

\noindent For production runs, it is recommended to use LOTUS (batch computing) rather than run interactively on the JASMIN analysis servers, which can become slow if there are many users running interactively at the same time. To run on LOTUS, the following job submission script example can be modified as required (submit using \texttt{"bsub < scriptName.sh"}). If processing 3-hourly or daily pp files, users should allow around 20-30 minutes of wall-clock time for each day to be processed; if processing monthly pp files, allow around 2-3 hours of wall-clock time for each month to be processed.\\
\hrule
\begin{spacing}{1}
\begin{lstlisting}
#!/bin/bash
#BSUB -q short-serial
#BSUB -J pp2nc_AOD550_CDN
#BSUB -o pp2nc_AOD550_CDN.out 
#BSUB -e pp2nc_AOD550_CDN.err 
#BSUB -W 05:00
./pp2nc_AOD550_CDN.py 3hrly /ppRoot/path /orogFile/path /ncRef/path ...
  ... /ncRoot/path 20080701 20080710
\end{lstlisting}
\end{spacing}
\hrule

\subsubsection{Output}
Running the script will generate two netCDF files (one for AOD and one for CDN) per day (for 3-hourly or daily pp files) or month (for monthly pp files) of processed data. The files will be written to the directory specified by the user through the `ncRoot' command-line argument. The naming convention of the files is `\texttt{[aod550/cdn]\_tebaa-tebiz\_teafw\_pbYYYYMMDD\_N48.nc}' if processing 3-hourly pp files, `\texttt{[aod550/cdn]\_tebaa-tebiz\_teafw\_paYYYYMMDD\_N48.nc}' if processing daily pp files, or `\texttt{[aod550/cdn]\_tebaa-tebiz\_teafw\_pmYYYYmon\_N48.nc}' if processing monthly pp files. The first part refers to the main variable within the file, the next parts refer to the start, end and median job ids, the \texttt{`pb'/`pa'/`pm'} part indicates 3-hourly/daily/monthly model data, the date stamp refers to the date of the data within the file, and the `\texttt{N48}' part references the grid resolution. A log file (`\texttt{logfile.log}') is also generated, which can be used to keep track of the script's progress during execution, as well as to check for any generated error/warning messages.

\subsubsection{Further details}
The script expects the input pp files to have the following directory structure/filename convention:\\
\tab \texttt{/ppRoot/<jobid>/<jobid>a.pbYYYYDDMM.pp} \hspace{1cm} for 3-hourly pp files,\\
\tab \texttt{/ppRoot/<jobid>/<jobid>a.paYYYYDDMM.pp} \hspace{1cm} for daily pp files, or\\
\tab \texttt{/ppRoot/<jobid>/<jobid>a.pmYYYYmon.pp} \hspace{1cm} for monthly pp files,\\
where \texttt{mon} is in the format `jan', `feb', etc.
The main root directory `ppRoot' is provided as a command line argument.\\\\

\noindent The script also expects the dimensions of the data within each input file to have certain size and order, as detailed below.
\begin{itemize}
\item For 3-hourly pp files:
\begin{itemize}
\item The CDNC field (expected stash ID: m01s38i479) is expected to have dimensions (nt, nz, nlat, nlon) = (8, 52, 145, 192)
\item The six AOD550 `mode' fields (expected stash IDs: m01s02i500 to m01s02i505) are expected to have dimensions (nt, nlat, nlon)=(8, 145, 192)\footnote{Although the script expects 8 timesteps per day, it has also been designed to deal with the case where there are only 7 timesteps in the six AOD modes. This is because some of the pp files for the first day of a calendar month have been found to have missing data for first AOD timestep (00:20). When this occurs, the 00:20 field is re-inserted into the output netCDF file and filled with missing values (NaN) so that the grid remains regular (as is necessary). As an example, there are 16 (out of 235) PPE members with a missing first timestep on 2008-07-01}
\end{itemize}
\item For daily pp files:
\begin{itemize}
\item The CDNC field (expected stash ID: m01s38i479) is expected to have dimensions (nz, nlat, nlon)=(52, 145, 192)
\item The six AOD550 `mode' fields (expected stash IDs: m01s02i500 to m01s02i505) are expected to have dimensions (n$\lambda$, nlat, nlon) = (6, 145, 192), with wavelengths $\lambda$ = 380, 440, 550, 670, 860, and 1020 nm (in that order).
\end{itemize}
\item For monthly pp files:
\begin{itemize}
\item The CDNC field (expected stash ID: m01s38i479) is expected to have dimensions (nz, nlat, nlon)=(85, 145, 192)
\item The six AOD550 `mode' fields (expected stash IDs: m01s02i500 to m01s02i505) are expected to have dimensions (n$\lambda$, nlat, nlon) = (6, 145, 192), with wavelengths $\lambda$ = 380, 440, 550, 670, 860, and 1020 nm (in that order).
\end{itemize}
\item The coarse resolution (N48) reference data file (`ncRef') and orography file (`orogFile') are expected to have dimensions (nlat, nlon) = (73, 96)
\end{itemize}

\noindent The 550nm AOD fields are calculated on the fine domain (N96) as the sum over the six `modes'. The column-integrated CDNC fields (i.e. CDN per m$^2$) are calculated on the fine domain by first multiplying each CDNC value by its cell height and then summing over all cells within a given model column. The cell heights are currently obtained using IRIS's `HybridHeightFactory' function, which takes orography data and the model sigma levels as input and gives the altitude bounds of each grid cell as output. However, it is planned to also implement Masaru's alternative approach of using the pressure and theta fields along with the hydrostatic equation; the method to use at execution could be chosen via an optional command line flag.\\

\noindent The fine domain data is then regridded onto the coarser (N48) domain using IRIS's `regrid' function, where the coarse grid coordinates are extracted from the `ncRef' file (supplied via a command-line argument). The `Linear' regridding method is used and is currently the preferred method (over the alternative 'AreaWeighted' method) as it is believed that the UM output data represents quantities at the grid cell centres rather than a mean over the grid cell volume.\\

\noindent Efforts have been made to capture as many potential errors as possible in a graceful manner (i.e. with descriptive error/warning messages written to the log file). These include:
\begin{itemize}
\item Checking that the paths given in the command-line arguments exist
\item Checking that the date stamps given in the command-line arguments are in the expected format, with the start date preceding or equalling the end date.
\item Checking that the data cubes can be loaded by IRIS (if this fails, it is most likely due to a missing/unexpected STASH codes)
\item Checking that all the relevant data cube dimensions are as expected.
\end{itemize}


\end{document}